{
    "model_name_or_path": "./output/Qwen2-0.5B-CSFT-CiteULike",
    "dataset_name": "/kaggle/input/llm2rec-data/CiteULike/llm2rec_processed/item_titles.txt",
    "tokenizer_name": "Qwen/Qwen2-0.5B",
    "per_device_train_batch_size": 32,
    "per_device_eval_batch_size": 32,
    "gradient_accumulation_steps": 1,
    "do_train": true,
    "do_eval": false,
    "line_by_line": true,
    "max_seq_length": 128,
    "mask_token_type": "blank",
    "data_collator_type": "default",
    "mlm_probability": 0.2,
    "overwrite_output_dir": true,
    "output_dir": "./output/iem_stage1/Qwen2-0.5B-CiteULike-CSFT",
    "eval_strategy": "no",
    "save_strategy": "steps",
    "save_steps": 500,
    "stop_after_n_steps": 1000,
    "lora_r": null,
    "gradient_checkpointing": true,
    "torch_dtype": "bfloat16",
    "attn_implementation": "flash_attention_2",
    "trust_remote_code": true
}